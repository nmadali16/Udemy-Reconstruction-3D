{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ENwTUiD252mq"
   },
   "outputs": [],
   "source": [
    "#!unzip  data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "viC1qndF5wxa"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "import os\n",
    "import scipy.misc\n",
    "from scipy.optimize import least_squares\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sfm_utils import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QykTGj543PNH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Q4mHRlMS7iZ2"
   },
   "outputs": [],
   "source": [
    "image_data_dir = '../data/statue/'\n",
    "unit_test_camera_matrix = np.load('../data/unit_test_camera_matrix.npy')\n",
    "unit_test_image_matches = np.load('../data/unit_test_image_matches.npy')\n",
    "image_paths = [os.path.join(image_data_dir, 'images', x) for x in sorted(os.listdir('../data/statue/images')) if '.jpg' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6p-hbLFlBwrS"
   },
   "outputs": [],
   "source": [
    "im0 = cv2.imread(image_paths[0])\n",
    "im_height, im_width, _ = im0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1694856240226,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "A23_q4PiwjSN",
    "outputId": "69386901-9f30-44d8-d0f2-1a5924d0dd03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "2CF38oWj7j-Y"
   },
   "outputs": [],
   "source": [
    "\n",
    "focal_length = 719.5459\n",
    "matches_subset = np.load(os.path.join(image_data_dir,'matches_subset.npy'), allow_pickle=True,encoding='latin1')[0,:]\n",
    "dense_matches = np.load(os.path.join(image_data_dir, 'dense_matches.npy'),allow_pickle=True,encoding='latin1')\n",
    "fundamental_matrices = np.load(os.path.join(image_data_dir,'fundamental_matrices.npy'),allow_pickle=True,encoding='latin1')[0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1694856242530,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "lQCOWFAmvpE0",
    "outputId": "c19a0286-a1e1-4aa7-cf4d-2ff1e3eb791d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(matches_subset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1694856243234,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "rxT_-oMgwm1w",
    "outputId": "dca0625a-93a3-4248-cbc6-1aca4e451922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 50)\n"
     ]
    }
   ],
   "source": [
    "print(matches_subset[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1694856244020,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "DhUFGSVCH15o",
    "outputId": "7280fdde-9a32-45d1-9c16-5607f985e124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 50)\n",
      "(4, 53)\n",
      "(4, 63)\n",
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(matches_subset)):\n",
    "  print(matches_subset[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1694856244871,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "7IkRmhvnvs9y",
    "outputId": "ea43347b-1fb8-4c3d-b1ae-6e416bf09410"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "print(dense_matches.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0h17bSXh5xEn"
   },
   "source": [
    "La représentation angle-axe, aussi appelée représentation axe-angle, est une façon de représenter une rotation en 3D en utilisant un axe de rotation et un angle de rotation autour de cet axe. C'est une représentation souvent plus intuitive qu'une matrice de rotation dans certains cas.\n",
    "\n",
    "Pour convertir une matrice de rotation en représentation angle-axe, vous pouvez suivre ces étapes :\n",
    "\n",
    "1. **Trouver l'axe de rotation** :\n",
    "\n",
    "   L'axe de rotation peut être extrait directement de la matrice de rotation. Si $ R $ est votre matrice de rotation, l'axe de rotation $ \\mathbf{n} $ peut être calculé comme suit :\n",
    "\n",
    "   $$\\mathbf{n} = \\frac{1}{2\\sin(\\theta)} \\begin{bmatrix} r_{32} - r_{23} \\\\ r_{13} - r_{31} \\\\ r_{21} - r_{12} \\end{bmatrix} $$\n",
    "\n",
    "   Où $ r_{ij} $ représente les éléments de la matrice de rotation.\n",
    "\n",
    "2. **Calculer l'angle de rotation** :\n",
    "\n",
    "   L'angle $ \\theta $ peut être calculé comme :\n",
    "\n",
    "   $$\\theta = \\arccos\\left(\\frac{\\text{trace}(R) - 1}{2}\\right) $$\n",
    "\n",
    "   où $\\text{trace}(R)$ est la somme des éléments diagonaux de la matrice de rotation.\n",
    "\n",
    "3. **Normaliser l'axe** :\n",
    "\n",
    "   Il est important de s'assurer que l'axe $ \\mathbf{n} $ soit un vecteur unitaire. Vous pouvez le faire en divisant chaque composante de $ \\mathbf{n} $ par sa magnitude :\n",
    "\n",
    "   $$\\mathbf{n} = \\frac{\\mathbf{n}}{\\|\\mathbf{n}\\|} $$\n",
    "\n",
    "La représentation résultante est $ (\\mathbf{n}, \\theta) $, où $ \\mathbf{n} $ est le vecteur unitaire représentant l'axe de rotation, et $ \\theta $ est l'angle de rotation autour de cet axe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "lTRnT0uu-Ju5"
   },
   "outputs": [],
   "source": [
    "class Frame:\n",
    "    def __init__(self, matches, focal_length, F, im_width, im_height):\n",
    "        self.focal_length = focal_length\n",
    "        self.im_height = im_height\n",
    "        self.im_width = im_width\n",
    "        self.matches = matches\n",
    "\n",
    "        self.N = matches.shape[0]\n",
    "        self.match_idx = np.array([np.arange(self.N), np.arange(self.N, 2 * self.N)])\n",
    "        self.match_points = np.vstack((matches[:,:2], matches[:,2:]))\n",
    "\n",
    "        self.K = np.eye(3)\n",
    "        self.K[0,0] = self.K[1,1] = focal_length\n",
    "        self.E = self.K.T.dot(F).dot(self.K)\n",
    "        self.T = estimate_RT_from_E(self.E, matches.reshape((-1,2,2)), self.K)\n",
    "\n",
    "        self.motion = np.zeros((2,3,4))\n",
    "        self.motion[0,:,:-1] = np.eye(3)\n",
    "        self.motion[1,:,:] = self.T\n",
    "        self.structure = triangulate(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8ps5ZpAZTRb"
   },
   "source": [
    "* Pour stocker les points et les correspondances, nous allons créer deux matrices :\n",
    "* La première contenant tous les points des deux images\n",
    "$$P=\\begin{bmatrix}\n",
    "p_{11}\\\\\n",
    "p_{12}\\\\\n",
    "\\vdots\\\\\n",
    "p_{1n}\\\\\n",
    "p_{21}\\\\\n",
    "p_{22}\\\\\n",
    "\\vdots\\\\\n",
    "p_{2n}\\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "* Est la correspondance avec les colonnes qui indiquent la caméra utilisée et la seconde est l'indice des points dans la première matrice.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & n+1 \\\\\n",
    "2 & n+2\\\\\n",
    "\\vdots & \\\\\n",
    "n & 2*n\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gioVbHO2Ns36"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1tH0thXNuZj"
   },
   "source": [
    "Frame 1 : Image 1 -> Image 2\n",
    "\n",
    "Frame 2 : Image 2 -> Image 3\n",
    "\n",
    "Correspandance : Image 1 -> Image 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3P8XM9RraYHL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5069,
     "status": "ok",
     "timestamp": 1694856253910,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "3tH5LcWxAm5a",
    "outputId": "1c29506e-e5d7-400a-dc30-f0b350de56ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nmadali\\Documents\\Udemy-Reconstruction-3D\\Chapitre 5\\triangulation.py:197: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  P_homo = np.array([P[0], P[1], P[2], 1.0])\n"
     ]
    }
   ],
   "source": [
    "frames = [0] * (len(image_paths) - 1)\n",
    "for i in range(len(image_paths)-1):\n",
    "        frames[i] = Frame(matches_subset[i].T, focal_length,\n",
    "                fundamental_matrices[i], im_width, im_height)\n",
    "        bundle_adjustment(frames[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1694856253910,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "wUFl_HGHIB5Y",
    "outputId": "2f751646-eeef-4b61-a371-924ced03db12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n",
      "(2, 53)\n",
      "(2, 63)\n",
      "(2, 32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(image_paths)-1):\n",
    "  print(frames[i].match_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Zsk_2VuAJcMH"
   },
   "outputs": [],
   "source": [
    "frameA=frames[0]\n",
    "frameB=frames[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AGTb_aQaxtR"
   },
   "source": [
    "* Pour fusionner les points de correspondance entre les deux images, nous commençons par trouver les points qui sont similaires entre les images, puis nous ajoutons seulement les points de la troisième image à notre liste de points de correspondance, en les ajoutant en premier à la liste des points.\n",
    "\n",
    "$$P=\\left [ P, \\begin{bmatrix}\n",
    "p_{31}\\\\\n",
    "p_{32}\\\\\n",
    "\\vdots \\\\\n",
    "p_{3,c}\n",
    "\\end{bmatrix}\\right ]$$\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & n+1& 2*n +1 \\\\\n",
    "2 & n+2& -1\\\\\n",
    "\\vdots && \\vdots \\\\\n",
    "n & 2*n& 2*n +c\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Ks_U3aH6Tyzq"
   },
   "outputs": [],
   "source": [
    "merged_frame = deepcopy(frameA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1694856253910,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "PjzzcUIbJuwW",
    "outputId": "6ac304d6-9be0-4057-b5a3-c08f7af59f4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n"
     ]
    }
   ],
   "source": [
    "print(frameA.match_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zIrsq1DUJ8pb"
   },
   "outputs": [],
   "source": [
    "trA = np.where(frameA.match_idx[0,:] >= 0)[0] # point cle sur la deuxieme image de la frame 1 donc la premiere  de la frame 1\n",
    "xyA = frameA.match_points[frameA.match_idx[-1, trA], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "cmUREl90KFUZ"
   },
   "outputs": [],
   "source": [
    "trB = np.where(frameB.match_idx[0,:] >= 0)[0] # point cle sur la premier image de la frame 2 donc la deuxieme de la frame 1\n",
    "xyB = frameB.match_points[frameB.match_idx[0, trB], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "ZZGWUfsQKQD6"
   },
   "outputs": [],
   "source": [
    "def row_intersection(A, B):\n",
    "    nrows, ncols = A.shape\n",
    "    dtype={'names':['f{}'.format(i) for i in range(ncols)],\n",
    "                   'formats':ncols * [A.dtype]}\n",
    "    intersect = np.intersect1d(A.view(dtype), B.view(dtype))\n",
    "    intersect = intersect.view(A.dtype).reshape((-1,ncols))\n",
    "    idA = np.array([np.where(np.all(A==x, axis=1))[0][0] for x in intersect])\n",
    "    idB = np.array([np.where(np.all(B==x, axis=1))[0][0] for x in intersect])\n",
    "    return intersect, idA, idB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ymuhAC7LLhJM"
   },
   "outputs": [],
   "source": [
    "xy_common, iA, iB = row_intersection(xyA, xyB)\n",
    "xy_common = xy_common.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "i198pDsjNZuJ"
   },
   "outputs": [],
   "source": [
    "#Ajoute une camera\n",
    "merged_frame.match_idx = np.vstack((merged_frame.match_idx, neg_ones((1, merged_frame.match_idx.shape[1]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "fSuPJftAT3dC"
   },
   "outputs": [],
   "source": [
    "#0 -> 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1694856338987,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "6p18SpDwT0Vj",
    "outputId": "c5271b86-2804-4ddc-e139-ef64109548f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 50)\n"
     ]
    }
   ],
   "source": [
    "print(merged_frame.match_idx.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1694854660077,
     "user": {
      "displayName": "nabil bcom",
      "userId": "04169804032469069549"
     },
     "user_tz": -120
    },
    "id": "_3WX6fM_Nahd",
    "outputId": "b190c5ef-f9f0-4868-eace-5884616af6f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_frame.match_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "LvTAWxJaNehc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Frame at 0x2110166dfa0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "1Jn2dmiVT-1L"
   },
   "outputs": [],
   "source": [
    "length=1+1 #index de la nouvelle camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vZuLKuOMLju1"
   },
   "outputs": [],
   "source": [
    "# faire correspendre les points de la premier image de la frame 1 avec ceux de la deuxieme image de la frame 2\n",
    "for i in range(xy_common.shape[1]):\n",
    "        idA = trA[iA[i]]\n",
    "        idB = trB[iB[i]]\n",
    "\n",
    "        B_match_idx = frameB.match_idx[1, idB]\n",
    "        # (camera 2, idx point in camera 1)=corespandance in camera 2\n",
    "        merged_frame.match_points = np.vstack((merged_frame.match_points, frameB.match_points[B_match_idx, :]))\n",
    "        merged_frame.match_idx[length, idA] = merged_frame.match_points.shape[0]-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "cs50pZAfUZl8"
   },
   "outputs": [],
   "source": [
    "# L'une des caméras de l'image B est la même que celle de l'image A.\n",
    "# Nous ajouterons tous les nouveaux points de cette caméra dans les champs de correspondance\n",
    "xy_new, iB, iA = row_set_diff(xyB, xyA)\n",
    "xy_new = xy_new.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9kXeFcFcVv8"
   },
   "source": [
    "* Nous devons également ajouter les points qui ne correspondent pas entre les trois images, dans ce cas en ajoutant les points de départ et d'arrivée de la deuxième et de la troisième caméra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "ipKN5ZwVP_VQ"
   },
   "outputs": [],
   "source": [
    "def row_set_diff(A, B):\n",
    "    nrows, ncols = A.shape\n",
    "    dtype={'names':['f{}'.format(i) for i in range(ncols)],\n",
    "                   'formats':ncols * [A.dtype]}\n",
    "    set_diff = np.setdiff1d(A.view(dtype), B.view(dtype))\n",
    "    set_diff = set_diff.view(A.dtype).reshape((-1,ncols))\n",
    "    idA = []\n",
    "    idB = []\n",
    "    for x in set_diff:\n",
    "        idx_in_A = np.where(np.all(A==x, axis=1))[0]\n",
    "        idx_in_B = np.where(np.all(B==x, axis=1))[0]\n",
    "        if len(idx_in_A) != 0:\n",
    "            idA.append(idx_in_A[0])\n",
    "        if len(idx_in_B) != 0:\n",
    "            idB.append(idx_in_B[0])\n",
    "\n",
    "    return set_diff, np.array(idA), np.array(idB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Lz28YKqBJu3p"
   },
   "outputs": [],
   "source": [
    "for i in range(xy_new.shape[1]):\n",
    "        idB = trB[iB[i]]\n",
    "\n",
    "        merged_frame.match_points = np.vstack((merged_frame.match_points,frameB.match_points[frameB.match_idx[0,idB],:]))\n",
    "        merged_frame.match_idx = np.hstack((merged_frame.match_idx, neg_ones((merged_frame.match_idx.shape[0],1))))\n",
    "        merged_frame.match_idx[length-1,-1] = merged_frame.match_points.shape[0]-1\n",
    "\n",
    "        merged_frame.structure = np.vstack((merged_frame.structure, frameB.structure[idB,:]))\n",
    "\n",
    "\n",
    "        B_match_idx = frameB.match_idx[1, idB]\n",
    "        merged_frame.match_points = np.vstack((merged_frame.match_points, frameB.match_points[B_match_idx,:]))\n",
    "        merged_frame.match_idx[length,-1] = merged_frame.match_points.shape[0]-1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a74ETZPZH_6x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "Rf8jLU5JAw3M"
   },
   "outputs": [],
   "source": [
    "def merge_two_frames(frameA, frameB, length):\n",
    "    merged_frame = deepcopy(frameA)\n",
    "\n",
    "    frameB_to_A = multiply_transformations(inverse(frameA.motion[-1,:,:]), frameB.motion[0,:,:])\n",
    "    frameB.structure = transform_points(frameB.structure, frameB_to_A)\n",
    "    for i in range(2):\n",
    "        frameB.motion[i,:,:] = multiply_transformations(frameB.motion[i,:,:], inverse(frameB_to_A))\n",
    "\n",
    "    # puisque la caméra se trouve dans le cadre de référence fusionné, l'ajouter à la matrice de mouvement\n",
    "    merged_frame.motion = np.vstack((merged_frame.motion, frameB.motion[-1,:,:].reshape((-1,3,4))))\n",
    "\n",
    "    # nous devons réconcilier les points appariés pour générer la structure.\n",
    "    # Nous devons fusionner les points appariés de chaque image supplémentaire, mais nous devons associer les points qui correspondent à des points déjà vus dans la même image.\n",
    "    # associer les points qui correspondent à des points déjà vus dans la même\n",
    "    # colonne\n",
    "    trA = np.where(frameA.match_idx[0,:] >= 0)[0]\n",
    "    xyA = frameA.match_points[frameA.match_idx[-1, trA], :]\n",
    "\n",
    "    trB = np.where(frameB.match_idx[0,:] >= 0)[0]\n",
    "    xyB = frameB.match_points[frameB.match_idx[0, trB], :]\n",
    "\n",
    "    xy_common, iA, iB = row_intersection(xyA, xyB)\n",
    "    xy_common = xy_common.T\n",
    "\n",
    "    merged_frame.match_idx = np.vstack((merged_frame.match_idx, neg_ones((1, merged_frame.match_idx.shape[1]))))\n",
    "    for i in range(xy_common.shape[1]):\n",
    "        idA = trA[iA[i]]\n",
    "        idB = trB[iB[i]]\n",
    "\n",
    "        B_match_idx = frameB.match_idx[1, idB]\n",
    "\n",
    "        merged_frame.match_points = np.vstack((merged_frame.match_points, frameB.match_points[B_match_idx, :]))\n",
    "        merged_frame.match_idx[length, idA] = merged_frame.match_points.shape[0]-1\n",
    "\n",
    "    # L'une des caméras de l'image B est la même que celle de l'image A.\n",
    "    # Nous ajouterons tous les nouveaux points de cette caméra dans les champs de correspondance\n",
    "    xy_new, iB, iA = row_set_diff(xyB, xyA)\n",
    "    xy_new = xy_new.T\n",
    "\n",
    "    for i in range(xy_new.shape[1]):\n",
    "        idB = trB[iB[i]]\n",
    "\n",
    "        merged_frame.match_points = np.vstack((merged_frame.match_points,frameB.match_points[frameB.match_idx[0,idB],:]))\n",
    "        merged_frame.match_idx = np.hstack((merged_frame.match_idx, neg_ones((merged_frame.match_idx.shape[0],1))))\n",
    "        merged_frame.match_idx[length-1,-1] = merged_frame.match_points.shape[0]-1\n",
    "        merged_frame.structure = np.vstack((merged_frame.structure, frameB.structure[idB,:]))\n",
    "\n",
    "        B_match_idx = frameB.match_idx[1, idB]\n",
    "\n",
    "        merged_frame.match_points = np.vstack((merged_frame.match_points, frameB.match_points[B_match_idx,:]))\n",
    "        merged_frame.match_idx[length,-1] = merged_frame.match_points.shape[0]-1\n",
    "\n",
    "\n",
    "\n",
    "    return merged_frame\n",
    "\n",
    "\n",
    "def merge_all_frames(frames):\n",
    "    merged_frame = deepcopy(frames[0])\n",
    "    for i in range(1,len(frames)):\n",
    "        merged_frame = merge_two_frames(merged_frame, frames[i], i+1)\n",
    "        merged_frame.structure = triangulate(merged_frame)\n",
    "        bundle_adjustment(merged_frame)\n",
    "        remove_outliers(merged_frame, 10)\n",
    "        bundle_adjustment(merged_frame)\n",
    "\n",
    "    return merged_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "kltDIx_vArx6"
   },
   "outputs": [],
   "source": [
    "merged_frame = merge_all_frames(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMWQ2C+kqaDgOaRiEyD/Mpf",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
